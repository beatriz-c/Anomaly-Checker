{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7024a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------pre-processing---------------------------------------------------#\n",
    "\n",
    "#data loading\n",
    "import pandas as pd\n",
    "predata = pd.read_csv('traindata.csv', nrows = 400000) #aumentar nrows atÃ© rebentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b905bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(predata['ipaddress'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "893a9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(predata['cons_freq_ipaddress'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604b5394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(set(predata['cons_freq_ipaddress']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44ad11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete unnecessary columns\n",
    "predata.drop(predata.columns[0], axis = 1, inplace = True) \n",
    "\n",
    "predata.drop(['ID', 'rowid', 'clientid', 'client', 'fingerprint', 'description_originator', \n",
    "'description_beneficiary', 'dummy_var', '#fingerprint_30D', 'fingerprint_time_diff', 'clientid_ipaddress_30D', \n",
    "'clientid_fingerprint_30D', 'clientid_iban_orig_30D', 'clientid_iban_dest_30D', '#clientid_fingerprint_30D',\n",
    "'amount_ratio_avg_clientid_30D', 'amount_ratio_avg_iban_dest_30D', 'canal__MBE', 'canal__MBP', 'canal__NBE', \n",
    "'canal__NBP', 'canal__OBE', 'operativa__PAGSRV', 'operativa__TRFINT', 'operativa__TRFIPS', 'operativa__TRFITC', \n",
    "'operativa__TRFSEP', 'operativa__others', 'entity__3', 'entity__37','entity__469', 'entity__5623', 'entity__others', \n",
    "'browser_family__chrome', 'browser_family__chrome mobile', 'browser_family__edge', 'browser_family__firefox', \n",
    "'browser_family__ie', 'browser_family__mobile safari', 'browser_family__others', 'os_family__android', 'os_family__ios', \n",
    "'os_family__linux', 'os_family__mac os x', 'os_family__others', 'os_family__windows', 'trusted_indicator__0.0',\n",
    "'trusted_indicator__1.0', 'trusted_indicator__UNKNOWN', 'week', 'amount_ratio_avg_30D_per_clientid',\n",
    "'amount_ratio_max_30D_per_clientid', 'amount_over_account_balance', 'amount_is_integer', 'amount_categories',\n",
    "'cons_freq_fingerprint', 'cons_freq_clientid', 'cons_time_fingerprint'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91624f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns created by me\n",
    "predata['weekday'] = pd.to_datetime(predata['timestamp']).apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59643924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopped being necessary\n",
    "predata.drop(['timestamp'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9329518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove dots from ipaddress\n",
    "predata['ipaddress'] = predata['ipaddress'].apply(lambda x: \"\".join(x.split(\".\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0949a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert decimals to int \n",
    "cols_to_int = ['#clientid_30D', '#ipaddress_30D', '#iban_orig_30D', '#iban_dest_30D', 'clientid_time_diff',\n",
    "               'iban_dest_time_diff', '#clientid_ipaddress_30D', '#clientid_iban_orig_30D', '#clientid_iban_dest_30D']\n",
    "\n",
    "for col in cols_to_int:\n",
    "    predata[col] = predata[col].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6815fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add letter before number to distinguish between similar words from different columns\n",
    "cols = ['entity', 'reference', 'iban_orig', 'iban_dest', 'ipaddress', 'hour', 'is_fraud_cons', 'date', \n",
    "'cons_freq_ipaddress', '#clientid_30D', '#ipaddress_30D', '#iban_orig_30D', '#iban_dest_30D', 'clientid_time_diff', \n",
    "'iban_dest_time_diff', '#clientid_ipaddress_30D', '#clientid_iban_orig_30D', '#clientid_iban_dest_30D']\n",
    "\n",
    "identifier = ['e', 'r', 'io', 'id', 'ip', 'h', 'fc', 'd', 'cfi', 'ncd', 'nid', 'niod', 'nidd', 'ctd', 'idtd', 'ncid', \n",
    "'nciod', 'ncidd']\n",
    "\n",
    "for col in range(len(cols)):\n",
    "    predata[cols[col]] = predata[cols[col]].apply(lambda x: identifier[col] + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e3b022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert binary and UNKNOWN to words \n",
    "def apply_map(df, col, target_map):\n",
    "    df[col] = df[col].apply(lambda x: target_map.get(str(x)))\n",
    "\n",
    "cols_maps = [('is_fraud', {'0':'nfraud', '1':'fraud'}),\n",
    "             ('trusted_indicator', {'0.0':'ntrusted', '1.0':'trusted', 'UNKNOWN':'unknown'}),\n",
    "             ('is_mobile', {'False':'nmobile', 'True':'mobile'}),\n",
    "             ('is_tablet', {'False':'ntablet', 'True':'tablet'}),\n",
    "             ('is_pc', {'False':'npc', 'True':'pc'}),\n",
    "             ('is_touch', {'False':'ntouch', 'True':'touch'}),\n",
    "             ('is_bot', {'False':'nbot', 'True':'bot'}),\n",
    "             ('weekday', {'0':'seg', '1':'ter', '2':'qua', '3':'qui', '4':'sex', '5':'sab', '6':'dom'})]\n",
    "\n",
    "for comb in cols_maps:\n",
    "    apply_map(predata, comb[0], comb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99e60560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many frauds\n",
    "len(predata[predata['is_fraud'] == 'fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fabcf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399997"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many not frauds\n",
    "len(predata[predata['is_fraud'] == 'nfraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "004e6bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#amounts -> classes\n",
    "import numpy as np \n",
    "\n",
    "#automatic labels\n",
    "import string\n",
    "\n",
    "class LabelCategorizer():\n",
    "    def __init__(self, base_word = 'cat'):\n",
    "        self._alphabet_index = 0\n",
    "        self.base_word = base_word\n",
    "        self.current_word = self.base_word\n",
    "        self.shift = 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Class: Label Categorizer\\nBase word: ' + self.base_word + '\\nCurrent Word: ' + self.current_word\n",
    "\n",
    "    def get_next_word(self):\n",
    "        if self.shift > 0:\n",
    "            self.current_word = self.current_word[-1] + self.current_word[:-1]\n",
    "            self.shift -= 1\n",
    "        else:\n",
    "            self.current_word = self.current_word + string.ascii_lowercase[self._alphabet_index]\n",
    "            self._alphabet_index = (self._alphabet_index + 1) % len(string.ascii_lowercase)\n",
    "            self.shift = len(self.current_word) - 1\n",
    "\n",
    "        return self.current_word\n",
    "\n",
    "\n",
    "#replacement of the old columns with the new ones with classes \n",
    "def cutter (col, number, word, words_map):\n",
    "\n",
    "    bins_a = np.linspace(predata[col].min(), predata[col].max(), num = number)\n",
    "    bins_a[0] = bins_a[0]-1\n",
    "    bins_aux = bins_a[1:]\n",
    "    bins_aux = np.append(bins_aux, bins_a[-1]+1)\n",
    "    bin_tuples = list(zip(bins_a, bins_aux))\n",
    "\n",
    "    bins = pd.IntervalIndex.from_tuples(bin_tuples)\n",
    "\n",
    "    labels_a = []\n",
    "\n",
    "    a = LabelCategorizer(base_word = word)\n",
    "\n",
    "    for _ in range(number):\n",
    "        labels_a.append(a.get_next_word())\n",
    "\n",
    "    x = pd.cut(predata[col].to_list(), bins = bins)\n",
    "    x.categories = labels_a\n",
    "    predata[col] = x\n",
    "\n",
    "    \n",
    "    for i in range(number):\n",
    "        words_map[labels_a[i]] = bins[i]       \n",
    "\n",
    "        \n",
    "columns = ['amount', 'accountbalance', 'mean_amount_clientid_30D', 'mean_amount_iban_dest_30D']\n",
    "number_bins = [100, 250, 100, 100]\n",
    "base_words = ['blue', 'pink', 'red', 'grey']\n",
    "\n",
    "#classes name -> interval\n",
    "values_map = {}\n",
    "\n",
    "for i in range (len(columns)):\n",
    "    cutter(columns[i], number_bins[i], base_words[i], values_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "076acb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#values_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bd226a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#values_map['pinka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bed04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(predata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eadc618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45bc8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower case\n",
    "predata['canal'] = predata['canal'].str.lower()\n",
    "predata['operativa'] = predata['operativa'].str.lower()\n",
    "predata['browser_family'] = predata['browser_family'].str.lower()\n",
    "predata['os_family'] = predata['os_family'].str.lower()\n",
    "predata['ipaddress'] = predata['ipaddress'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37f22225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#predata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20c540cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataframe to numpy array of arrays\n",
    "sentences = predata.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c7caba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "722a5e96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nbe', 'apgest', 'e3', 'r542046', 'ntrusted', 'io4', 'id3',\n",
       "       'bluea', 'nkapi', 'ip17218224250', 'nfraud', 'nmobile', 'ntablet',\n",
       "       'pc', 'ntouch', 'nbot', 'chrome', 'windows', 'ncd0', 'nid1056',\n",
       "       'niod0', 'nidd56720', 'ctd-1', 'idtd4', 'reda', 'greya', 'ncid0',\n",
       "       'nciod0', 'ncidd0', 'fc0', 'd20190806', 'h0', 'cfi1', 'ter'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20efc94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks = [type(elem) == str for elem in sentences[0]]\n",
    "#sum(checks) == len(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dedc7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(sentences[99][0]) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30378d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "517f5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = list(sentences)\n",
    "#np.savetxt('train_data.txt', sentences, delimiter=\" \", fmt=\"%s\")\n",
    "#sentences = w2v.LineSentence('train_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "081b417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_aux = [list(curr) for curr in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0aea1865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sentences_aux[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff4bc9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_series = pd.Series(sentences_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "add62c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback to print loss after each epoch\n",
    "\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import gensim.models.word2vec as w2v\n",
    "\n",
    "# init callback class\n",
    "class callback(CallbackAny2Vec):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        \n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        elif self.epoch % 100 == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss - self.loss_previous_step))\n",
    "        \n",
    "        \n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae36bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 5944069.0\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------training------------------------------------------------------#\n",
    "\n",
    "#inicialization and training word2vec\n",
    "import multiprocessing\n",
    "import gensim.models.word2vec as w2v\n",
    "\n",
    "def training (sentences, cycles, dim, architecture, context):\n",
    "    model = w2v.Word2Vec (\n",
    "        sg = architecture, #1 - skip-gram , 0 - cbow\n",
    "        workers = multiprocessing.cpu_count(), #uses all the cores \n",
    "        vector_size = dim, #dimension of the embedding space = N \n",
    "        window = context, #words befores and after center word\n",
    "        sample = 0, #whithout downsampling \n",
    "        ns_exponent = 0.0,\n",
    "        min_count = 0, \n",
    ")\n",
    "    \n",
    "    #vocabulary creation\n",
    "    model.build_vocab(sentences) \n",
    "\n",
    "    #model training\n",
    "    model.train(sentences, epochs = cycles, total_examples = model.corpus_count, compute_loss = True, callbacks = [callback()])\n",
    "\n",
    "    return model\n",
    "\n",
    "#model creation\n",
    "model = training(sentences_series, 5, 5, 1, 5) #usar 2, 5, 7, 10 para espaÃ§o do meio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04bbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ffcdc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(model.wv.index_to_key)) #vocab size = V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ca6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b91f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#words more related to not frauds\n",
    "#model.wv.most_similar('nfraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d8894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "model.save('Trained.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c874e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------matrices--------------------------------------------------------#\n",
    "\n",
    "#weight matrices\n",
    "m1 = model.wv.vectors  #input embedding matrix  #VxN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc1cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = model.syn1neg      #NxV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735af5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization of the matrices\n",
    "#np.set_printoptions(edgeitems = 10000)\n",
    "#np.set_printoptions(linewidth = 10000)\n",
    "np.set_printoptions(threshold = np.inf)\n",
    "\n",
    "#import sys\n",
    "#np.set_printoptions(threshold = sys.maxsize)\n",
    "\n",
    "#seeing the matrix\n",
    "#s = [[str(e) for e in row] for row in probabilities]\n",
    "#lens = [max(map(len, col)) for col in zip(*s)]\n",
    "#fmt = '\\t'.join('{{:{}}}'.format(x) for x in lens)\n",
    "#table = [fmt.format(*row) for row in s]\n",
    "#print ('\\n'.join(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6e8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m1.shape)\n",
    "#print(np.matrix(m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc42b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m2.shape)\n",
    "#print(np.matrix(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40182ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = np.transpose(m2)\n",
    "print(m3.shape)\n",
    "#print(np.matrix(m3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#product of the matrices\n",
    "probabilities = np.matmul(m1, m3)\n",
    "print(probabilities.shape)\n",
    "#print(np.matrix(probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca728341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditional probabilities - softmax\n",
    "#def softmax(x):\n",
    "#    y = np.exp(x - np.max(x))\n",
    "#    f_x = y / np.sum(np.exp(x))\n",
    "#    return f_x\n",
    "\n",
    "#all_probs = [max(softmax(curr)) for curr in probabilities]\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "all_probs = softmax(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b5fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.max(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d579e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there's negative numbers\n",
    "\n",
    "#for number in conditional_probabilities:\n",
    "#    if np.any(number) < 0:\n",
    "#        print('Something is wrong')\n",
    "#    else:\n",
    "#        print('All positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there numbers bigger than 1\n",
    "\n",
    "#for number in conditional_probabilities:\n",
    "#    if np.any(number) > 1:\n",
    "#        print('Something is wrong')\n",
    "#    else:\n",
    "#        print('All positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75834933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------LDA model----------------------------------------------------------#\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "#create dictionary\n",
    "id2word = corpora.Dictionary(sentences)\n",
    "\n",
    "#create corpus\n",
    "texts = sentences\n",
    "\n",
    "#term document frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "#human readable format of corpus (term-frequency)\n",
    "print([[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]) #so esta a fazer para a 1Âª linha\n",
    "\n",
    "#build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                           id2word = id2word,\n",
    "                                           num_topics = 20,\n",
    "                                           random_state = 100,\n",
    "                                           update_every = 1,\n",
    "                                           chunksize = 100,\n",
    "                                           passes = 100,\n",
    "                                           alpha = 'auto',\n",
    "                                           per_word_topics = True)\n",
    "\n",
    "\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9bbde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  #the lower the better.\n",
    "\n",
    "#compute coherence score                                 #higher the topic is more human interpretable\n",
    "coherence_model_lda = CoherenceModel(model = lda_model, texts = sentences, dictionary = id2word, coherence = 'c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e57015",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e18fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6927896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b6d531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
